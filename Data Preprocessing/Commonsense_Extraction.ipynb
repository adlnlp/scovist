{"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"HGqsLoq4lHEO"}},{"cell_type":"markdown","source":["## Packages and Downloading ATOMIC-2020"],"metadata":{"id":"y7JqbOaulbgq"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1163,"status":"ok","timestamp":1666067764318,"user":{"displayName":"Eileen","userId":"01091172001417006453"},"user_tz":-660},"id":"x_D3Gsfpffag","outputId":"52b39787-0541-4a14-f30f-bebe22f16a51"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'comet-atomic-2020'...\n","remote: Enumerating objects: 190, done.\u001b[K\n","remote: Counting objects: 100% (77/77), done.\u001b[K\n","remote: Compressing objects: 100% (38/38), done.\u001b[K\n","remote: Total 190 (delta 56), reused 42 (delta 39), pack-reused 113\u001b[K\n","Receiving objects: 100% (190/190), 7.15 MiB | 22.00 MiB/s, done.\n","Resolving deltas: 100% (74/74), done.\n"]}],"source":["!git clone https://github.com/allenai/comet-atomic-2020.git"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PNJA_0Naf1fK"},"outputs":[],"source":["### download pretrained model : https://github.com/allenai/comet-atomic-2020\n","!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" --header=\"Referer: https://github.com/allenai/comet-atomic-2020/issues/12\" \"https://storage.googleapis.com/ai2-mosaic-public/projects/mosaic-kgs/comet-atomic_2020_BART.zip\" -c -O 'comet-atomic_2020_BART.zip'\n","!unzip comet-atomic_2020_BART.zip\n","\n","!pip install -r comet-atomic-2020/requirements.txt\n","\n","### copy utils script to current directory\n","shutil.copy(\"comet-atomic-2020/models/comet_atomic2020_bart/utils.py\", \"/content/utils.py\")\n","\n","!pip install transformers==3.0.2"]},{"cell_type":"markdown","source":["## Imports"],"metadata":{"id":"mfLoKv4plhBD"}},{"cell_type":"code","source":["\n","import shutil\n","import torch\n","import argparse\n","import time \n","import datetime\n","from tqdm import tqdm\n","from pathlib import Path\n","from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n","from utils import calculate_rouge, use_task_specific_params, calculate_bleu_score, trim_batch\n"],"metadata":{"id":"RWyaihIGlIMY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0m8KI_LIfb-p"},"source":["# Atomic-2020"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vT5vqdrWhgAH"},"outputs":[],"source":["def chunks(lst, n):\n","    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n","    for i in range(0, len(lst), n):\n","        yield lst[i : i + n]\n","\n","\n","class Comet:\n","    def __init__(self, model_path):\n","        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_path).to(self.device)\n","        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n","        task = \"summarization\"\n","        use_task_specific_params(self.model, task)\n","        self.batch_size = 100\n","        self.decoder_start_token_id = None\n","\n","    def generate(\n","            self, \n","            queries,\n","            decode_method=\"beam\", \n","            num_generate=5, \n","            ):\n","\n","        with torch.no_grad():\n","            examples = queries\n","\n","            decs = []\n","            batch_idx = 0\n","            for batch in list(chunks(examples, self.batch_size)):\n","                \n","                time1 = datetime.datetime.now()\n","\n","                batch = self.tokenizer(batch, return_tensors=\"pt\", truncation=True, padding=\"max_length\").to(self.device)\n","                input_ids, attention_mask = trim_batch(**batch, pad_token_id=self.tokenizer.pad_token_id)\n","\n","                summaries = self.model.generate(\n","                    input_ids=input_ids,\n","                    attention_mask=attention_mask,\n","                    decoder_start_token_id=self.decoder_start_token_id,\n","                    num_beams=num_generate,\n","                    num_return_sequences=num_generate\n","                    )\n","                dec = self.tokenizer.batch_decode(summaries, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n","                decs.append(dec)\n","\n","                time2 = datetime.datetime.now()\n","\n","                batch_idx += 1\n","                if (batch_idx % 50) == 0: \n","                    print(\"Processed batch: {}, time takens: {}\".format(batch_idx, (time2-time1).total_seconds()))\n","\n","\n","            return decs\n","\n","\n","all_relations = [\n","    \"AtLocation\",\n","    \"CapableOf\",\n","    \"Causes\",\n","    \"CausesDesire\",\n","    \"CreatedBy\",\n","    \"DefinedAs\",\n","    \"DesireOf\",\n","    \"Desires\",\n","    \"HasA\",\n","    \"HasFirstSubevent\",\n","    \"HasLastSubevent\",\n","    \"HasPainCharacter\",\n","    \"HasPainIntensity\",\n","    \"HasPrerequisite\",\n","    \"HasProperty\",\n","    \"HasSubEvent\",\n","    \"HasSubevent\",\n","    \"HinderedBy\",\n","    \"InheritsFrom\",\n","    \"InstanceOf\",\n","    \"IsA\",\n","    \"LocatedNear\",\n","    \"LocationOfAction\",\n","    \"MadeOf\",\n","    \"MadeUpOf\",\n","    \"MotivatedByGoal\",\n","    \"NotCapableOf\",\n","    \"NotDesires\",\n","    \"NotHasA\",\n","    \"NotHasProperty\",\n","    \"NotIsA\",\n","    \"NotMadeOf\",\n","    \"ObjectUse\",\n","    \"PartOf\",\n","    \"ReceivesAction\",\n","    \"RelatedTo\",\n","    \"SymbolOf\",\n","    \"UsedFor\",\n","    \"isAfter\",\n","    \"isBefore\",\n","    \"isFilledBy\",\n","    \"oEffect\",\n","    \"oReact\",\n","    \"oWant\",\n","    \"xAttr\",\n","    \"xEffect\",\n","    \"xIntent\",\n","    \"xNeed\",\n","    \"xReact\",\n","    \"xReason\",\n","    \"xWant\",\n","    ]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14899,"status":"ok","timestamp":1666067885141,"user":{"displayName":"Eileen","userId":"01091172001417006453"},"user_tz":-660},"id":"b8ZMgpJ62TCO","outputId":"31352567-8292-41d1-b845-79f8d3d620a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["model loading ...\n","model loaded\n"]}],"source":["# sample usage (reproducing demo)\n","print(\"model loading ...\")\n","comet = Comet(\"./comet-atomic_2020_BART\")\n","comet.model.zero_grad()\n","print(\"model loaded\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3761,"status":"ok","timestamp":1666067890756,"user":{"displayName":"Eileen","userId":"01091172001417006453"},"user_tz":-660},"id":"kBnDWGNu6poY","outputId":"f2bee55c-db85-4bb0-b063-3f58064a929c"},"outputs":[{"output_type":"stream","name":"stdout","text":["['a bouquet of white peonies in a vase xNeed [GEN]']\n","[[' put in vase', ' bring to the store', ' bring to the party', ' to buy', ' buy']]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:730: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  beam_id = beam_token_id // vocab_size\n"]}],"source":["queries = []\n","head = \"a bouquet of white peonies in a vase\"\n","rel = \"xNeed\"\n","query = \"{} {} [GEN]\".format(head, rel)\n","queries.append(query)\n","print(queries)\n","results = comet.generate(queries, decode_method=\"beam\", num_generate=5)\n","print(results)"]},{"cell_type":"markdown","metadata":{"id":"oiftHbMpvNA5"},"source":["# Extract Commonsense\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-A0QgUBpYZ3c"},"outputs":[],"source":["caption_type = \"CLIP\" #@param [\"CLIP\", \"OFA\", \"BLIP\"]\n","split = \"train\" #@param [\"train\", \"valid\", \"test\"]\n","BEAM_SIZE = 5 #@param\n","\n","captions = json.load(open(\"/content/{}_captions.json\".format(caption_type)))\n","stories = json.load(open(\"/content/{}_stories.json\".format(split)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1666070509195,"user":{"displayName":"Eileen","userId":"01091172001417006453"},"user_tz":-660},"id":"9SSjcvL_gUzn","outputId":"52fa54dd-5c1a-412c-f0b2-659dbda7e62d"},"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 393 ms, sys: 1.01 ms, total: 394 ms\n","Wall time: 393 ms\n"]}],"source":["%%time\n","keys = list(stories.keys())\n","\n","heads = []\n","\n","for key in keys: \n","    story = stories[key]['story']\n","    images = stories[key]['images']\n","\n","    image_formats = ['.jpg', '.gif', '.png', '.bmp']\n","\n","    for img in images: \n","        for f in image_formats: \n","            img_name = img + f \n","            try:\n","                caption = captions[img_name]\n","                if caption[-1] == \".\":\n","                    caption = caption[:-1] \n","                if caption == '': continue\n","                heads.append(caption)\n","            except: \n","                continue "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1666070509872,"user":{"displayName":"Eileen","userId":"01091172001417006453"},"user_tz":-660},"id":"LWfperAuj2Ve","outputId":"0d47fc83-e293-46f7-ea6f-014c8cce23cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["200746\n","34204\n"]}],"source":["print(len(heads))\n","heads = list(set(heads))\n","print(len(heads))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1666070511699,"user":{"displayName":"Eileen","userId":"01091172001417006453"},"user_tz":-660},"id":"XT9s7tCIvsTY","outputId":"7a62007e-3764-4edc-c285-f87dc5a5dc49"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of queries: 273632\n"]}],"source":["queries = []\n","rels = [\"AtLocation\", \"CapableOf\", \"xNeed\", \"xIntent\", \"xWant\", \"xEffect\", \"xReact\", \"xAttr\"]\n","\n","for head in heads: \n","    for rel in rels:\n","        query = \"{} {} [GEN]\".format(head, rel)\n","        queries.append(query)\n","\n","print(\"Number of queries: {}\".format(len(queries)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5964648,"status":"ok","timestamp":1666076478518,"user":{"displayName":"Eileen","userId":"01091172001417006453"},"user_tz":-660},"id":"BhVaFcm-kYAo","outputId":"8176d314-b799-4f06-e5c9-1b800e38e55e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Processed batch: 50, time takens: 2.154699\n","Processed batch: 100, time takens: 2.743159\n","Processed batch: 150, time takens: 2.00381\n","Processed batch: 200, time takens: 2.104369\n","Processed batch: 250, time takens: 2.260292\n","Processed batch: 300, time takens: 2.217628\n","Processed batch: 350, time takens: 2.484714\n","Processed batch: 400, time takens: 2.436287\n","Processed batch: 450, time takens: 2.25503\n","Processed batch: 500, time takens: 2.143347\n","Processed batch: 550, time takens: 2.023096\n","Processed batch: 600, time takens: 2.247681\n","Processed batch: 650, time takens: 2.144781\n","Processed batch: 700, time takens: 2.653079\n","Processed batch: 750, time takens: 2.046963\n","Processed batch: 800, time takens: 2.300652\n","Processed batch: 850, time takens: 2.140453\n","Processed batch: 900, time takens: 1.99728\n","Processed batch: 950, time takens: 2.123757\n","Processed batch: 1000, time takens: 2.287488\n","Processed batch: 1050, time takens: 2.440983\n","Processed batch: 1100, time takens: 2.099444\n","Processed batch: 1150, time takens: 2.123943\n","Processed batch: 1200, time takens: 2.112523\n","Processed batch: 1250, time takens: 2.282813\n","Processed batch: 1300, time takens: 2.04458\n","Processed batch: 1350, time takens: 2.227951\n","Processed batch: 1400, time takens: 2.136215\n","Processed batch: 1450, time takens: 2.080185\n","Processed batch: 1500, time takens: 2.200126\n","Processed batch: 1550, time takens: 2.343675\n","Processed batch: 1600, time takens: 2.170014\n","Processed batch: 1650, time takens: 2.245305\n","Processed batch: 1700, time takens: 2.138779\n","Processed batch: 1750, time takens: 2.39861\n","Processed batch: 1800, time takens: 2.285728\n","Processed batch: 1850, time takens: 2.433446\n","Processed batch: 1900, time takens: 2.64252\n","Processed batch: 1950, time takens: 2.19854\n","Processed batch: 2000, time takens: 2.295173\n","Processed batch: 2050, time takens: 2.300661\n","Processed batch: 2100, time takens: 2.006909\n","Processed batch: 2150, time takens: 1.995162\n","Processed batch: 2200, time takens: 2.169011\n","Processed batch: 2250, time takens: 2.021551\n","Processed batch: 2300, time takens: 2.337728\n","Processed batch: 2350, time takens: 2.018615\n","Processed batch: 2400, time takens: 2.287022\n","Processed batch: 2450, time takens: 2.28025\n","Processed batch: 2500, time takens: 2.09203\n","Processed batch: 2550, time takens: 2.25559\n","Processed batch: 2600, time takens: 2.126072\n","Processed batch: 2650, time takens: 2.286105\n","Processed batch: 2700, time takens: 2.133274\n","CPU times: user 1h 39min 32s, sys: 10.6 s, total: 1h 39min 43s\n","Wall time: 1h 39min 24s\n"]}],"source":["%%time \n","results = comet.generate(queries, decode_method=\"beam\", num_generate=BEAM_SIZE) # takes 3 hours for training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1666076478519,"user":{"displayName":"Eileen","userId":"01091172001417006453"},"user_tz":-660},"id":"XT14R3XZD-pf","outputId":"74ecb545-8882-40f6-8dbd-c2a59fd081e9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["273632"]},"metadata":{},"execution_count":24}],"source":["all_results = [item for sublist in results for item in sublist]\n","assert len(queries) * BEAM_SIZE == len(all_results)\n","len(queries)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2163,"status":"ok","timestamp":1666076480679,"user":{"displayName":"Eileen","userId":"01091172001417006453"},"user_tz":-660},"id":"-kEui89GZ1a8","outputId":"52028e6a-d214-4602-96a0-57c057ba53d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["273632\n"]}],"source":["### save results \n","data_dict = {} \n","\n","r_idx = 0\n","for i in range(len(queries)): \n","    data_dict[queries[i]] = all_results[r_idx:r_idx+BEAM_SIZE]\n","    r_idx += BEAM_SIZE\n","    assert len(data_dict[queries[i]]) == BEAM_SIZE\n","\n","print(len(data_dict))\n","\n","with open(\"/content/Atomic2020/{}_{}_comet_ck.json\".format(caption_type, split), \"w\") as outfile:\n","    json.dump(data_dict, outfile)"]},{"cell_type":"markdown","metadata":{"id":"LND4dJGX0nTd"},"source":["# Reformat Commonsense to Dictionary Format"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4GLSeYrq1WGD"},"outputs":[],"source":["def get_cap_and_imgs(stories, story_id, img2cap, cap_type = \"VIST\", display = False): \n","    \"\"\"\n","    Retrieve the image names and corresponding captions \n","    for given story id. \n","    \"\"\"\n","\n","    if str(story_id) not in stories:\n","        print(\"This story id does not exist.\")\n","        return\n","\n","    story = stories[str(story_id)]['story']\n","    images = stories[str(story_id)]['images']\n","\n","    image_formats = ['.jpg', '.gif', '.png', '.bmp']\n","    image_list = [] \n","    cap_list = []\n","\n","    for img in images: \n","\n","        for f in image_formats: \n","            if cap_type == \"VIST\":\n","                img_name = img \n","            else:\n","                img_name = img + f \n","            try:\n","                caption = img2cap[img_name]\n","                if display == True: \n","                    print(img_name, \":\" , caption)\n","                image_list.append(img_name)\n","                if cap_type == \"CLIP\":  # get rid of last full stop for CLIP captions\n","                    if caption[-1] == \".\": \n","                        cap_list.append(caption[:-1])\n","                    else:\n","                        cap_list.append(caption)\n","                else: \n","                    cap_list.append(caption)\n","            except: \n","                continue \n","\n","    return image_list, cap_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pTfge-HM0xb9"},"outputs":[],"source":["split = \"test\"\n","caption_type = \"CLIP\"\n","\n","cks = json.load(open(\"/content/{}_{}_comet_ck.json\".format(caption_type, split)))\n","stories = json.load(open(\"/content/{}_stories.json\".format(split)))\n","img2cap = json.load(open(\"/content/{}_captions.json\".format(caption_type)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WE9o_Vg704XQ"},"outputs":[],"source":["rels = [\"AtLocation\", \"CapableOf\", \"xNeed\", \"xIntent\", \"xWant\", \"xEffect\", \"xReact\", \"xAttr\"]\n","\n","cks_dict = {} \n","problem_stories = []\n","\n","for story_id in stories: \n","    _, cap_list = get_cap_and_imgs(stories, story_id, img2cap, cap_type = \"CLIP\")\n","    # cap_list = list(set(cap_list))\n","    if len(cap_list) != 5: \n","        problem_stories.append(story_id)\n","        continue\n","    temp = {} # [img_num : rels]\n","    for i in range(0, len(cap_list)): \n","        img_num = i\n","        image_ck = {} # rel: [ck1, ck2...]\n","        for rel in rels: \n","            key = cap_list[i] + \" \" + rel + \" \" + \"[GEN]\" \n","            common_sense = cks[key]\n","            common_sense = [x.strip() for x in common_sense if x != \" none\"]\n","            image_ck[rel] = common_sense \n","        image_ck[\"caption\"] = cap_list[i]\n","        temp[img_num] = image_ck \n","    cks_dict[story_id] = temp \n","print(len(problem_stories))\n","print(len(cks_dict))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rrp-8Ehf21zr"},"outputs":[],"source":["with open('cks_{}_{}.json'.format(caption_type, split), 'w') as f:\n","    json.dump(cks_dict, f)\n","\n","shutil.move(\"/content/cks_{}_{}.json\".format(caption_type, split),\n","            \"/content/Common Sense Dicts/cks_{}_{}.json\".format(caption_type, split))"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[{"file_id":"1nVzSvns9K1tY2CIG4eAhufL9EWCniTV5","timestamp":1677714848881},{"file_id":"1bgnaQ6bjCwtuH6e4AT4Ifu2tto0EPbKn","timestamp":1677714310455}],"toc_visible":true,"authorship_tag":"ABX9TyPOzWKwzAnfnj4ww9qJ8xV+"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}